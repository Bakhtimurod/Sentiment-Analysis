{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d61d004b-c608-40a1-b20a-305d42e8b02c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Step 1: Load the Data\n",
    "\n",
    "*    mount s3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7702f90e-f044-4311-b927-fc6f8b6d90e7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install vaderSentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8db1ec91-1481-464d-baaf-996c57dcdf8c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName('WeCloud Spark Training') \\\n",
    "        .getOrCreate()\n",
    "print('Session created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3216ac49-cd0c-4506-bc7e-49ad6d52f2e1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23fc9084-68d0-4587-9309-f64f5ce233ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def mount_s3_bucket(access_key, secret_key, bucket_name, mount_folder):\n",
    "  ACCESS_KEY_ID = access_key\n",
    "  SECRET_ACCESS_KEY = secret_key\n",
    "  ENCODED_SECRET_KEY = SECRET_ACCESS_KEY.replace(\"/\", \"%2F\")\n",
    "\n",
    "  print (\"Mounting\", bucket_name)\n",
    "\n",
    "  try:\n",
    "    # Unmount the data in case it was already mounted.\n",
    "    dbutils.fs.unmount(\"/mnt/%s\" % mount_folder)\n",
    "    \n",
    "  except:\n",
    "    # If it fails to unmount it most likely wasn't mounted in the first place\n",
    "    print (\"Directory not unmounted: \", mount_folder)\n",
    "    \n",
    "  finally:\n",
    "    # Lastly, mount our bucket.\n",
    "    dbutils.fs.mount(\"s3a://%s:%s@%s\" % (ACCESS_KEY_ID, ENCODED_SECRET_KEY, bucket_name), \"/mnt/%s\" % mount_folder)\n",
    "    #dbutils.fs.mount(\"s3a://\"+ ACCESS_KEY_ID + \":\" + ENCODED_SECRET_KEY + \"@\" + bucket_name, mount_folder)\n",
    "    print (\"The bucket\", bucket_name, \"was mounted to\", mount_folder, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ebd0a92-ac74-4c03-91d1-2997085c8b0d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set AWS programmatic access credentials\n",
    "ACCESS_KEY = \"AKIA4VDBMHXDRBOBMLXQ\"\n",
    "SECRET_ACCESS_KEY = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed476e18-3bf2-43dd-905b-e29469ae84d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mount_s3_bucket(ACCESS_KEY, SECRET_ACCESS_KEY, \"boqi-bucket\", \"chatgpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5709f0f6-087c-442b-9596-ddb3feedba65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List the files in the mounted directory\n",
    "dbutils.fs.ls(\"/mnt/chatgpt/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b54b783-c2f3-4b5d-ae4d-82c9e84c75b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls 'dbfs:/mnt/chatgpt/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13992f7b-32f4-4651-8d56-b83431c63be6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "\n",
    "Since We don't have any information about the dataset (like column names or data types), the best approach is to first preview the dataset before manually defining the schema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edaebe4c-6e86-4f8f-9366-985660bd14b7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 2: Create a Schema for Dataframe\n",
    "*       Define the schema of the dataset and create a Spark DataFrame accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8c354d5-bd67-46fa-b468-0c3a53f78d70",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType, TimestampType\n",
    "\n",
    "# Define the schema for the tweet dataset with appropriate data types\n",
    "schema = StructType([\n",
    "    StructField(\"tweet_id\", StringType(), True),\n",
    "    StructField(\"tweet_created\", StringType(), True),  # we can later convert this to TimestampType\n",
    "    StructField(\"tweet_extracted\", StringType(), True),  # Same for this\n",
    "    StructField(\"text\", StringType(), True),\n",
    "    StructField(\"lang\", StringType(), True),\n",
    "    StructField(\"user_id\", StringType(), True),\n",
    "    StructField(\"user_name\", StringType(), True),\n",
    "    StructField(\"user_username\", StringType(), True),\n",
    "    StructField(\"user_location\", StringType(), True),\n",
    "    StructField(\"user_description\", StringType(), True),\n",
    "    StructField(\"user_created\", StringType(), True),  # we can convert to TimestampType later if needed\n",
    "    StructField(\"user_followers_count\", IntegerType(), True),\n",
    "    StructField(\"user_following_count\", IntegerType(), True),\n",
    "    StructField(\"user_tweet_count\", IntegerType(), True),\n",
    "    StructField(\"user_verified\", BooleanType(), True),  # Boolean field\n",
    "    StructField(\"source\", StringType(), True),\n",
    "    StructField(\"retweet_count\", IntegerType(), True),\n",
    "    StructField(\"like_count\", IntegerType(), True),\n",
    "    StructField(\"reply_count\", IntegerType(), True),\n",
    "    StructField(\"impression_count\", IntegerType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74707c79-49a3-49e0-9868-5005b7e6a36a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame using the defined schema\n",
    "chatgpt_tweets_df = spark.read.option(\"header\", \"true\").schema(schema).csv(\"dbfs:/mnt/chatgpt/chatgpt_daily_tweets.csv\")\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "chatgpt_tweets_df.show(5)\n",
    "\n",
    "# Print the schema to verify that everything is correctly typed\n",
    "chatgpt_tweets_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d632505-b224-4c41-a6e6-f8817f4033a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Lets get familiar with the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d549d4f-4d31-4763-8628-d6a5ce9da3c1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# show the dataframe\n",
    "display(chatgpt_tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c8326fcd-8017-4bd6-a3e8-8a07e1776dfa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# show the column names \n",
    "chatgpt_tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13ce3f6d-f66b-4487-a8b4-82aab704026e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Count the number of rows in the DataFrame\n",
    "chatgpt_tweets_df.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3fb6f7c2-112a-4c64-aece-60db871fe092",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "018715bd-cd08-4d9e-b7b0-29773ce5341b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ced08b2-0cf0-4ba9-9564-8ff62bbacca4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 3: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8557a2f8-3a2b-465e-955c-601f0bc35547",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.1 Filter out empty rows\n",
    "*        Remove any rows with missing or empty values from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d656d697-4ae0-4e4b-b755-5cba1400d6a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# necessary libraries for preprocessing\n",
    "from pyspark.sql.functions import col, lower, regexp_replace, to_timestamp\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16ca885b-e2b5-4466-bbbd-91f23f064166",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filter out rows where 'text' is null or empty\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df.filter((col(\"text\").isNotNull()) & (col(\"text\") != \"\"))\n",
    "\n",
    "# Show the filtered DataFrame\n",
    "display(chatgpt_tweets_df_filtered)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e01451a6-a0f3-4d5c-8205-8dfbfe1a9c89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3.2 Clean and Preprocess text data\n",
    "\n",
    "*      Perform text preprocessing steps, such as:\n",
    "          *  Create a new column for the original text (original_text).\n",
    "          *  Convert tweet_created to datetime format.\n",
    "          *  Convert tweet text to lowercase.\n",
    "          *  Remove Twitter handles (e.g., @username).\n",
    "          *  Remove hashtags (e.g., #hashtag).\n",
    "          *  Remove URLs.\n",
    "          *  Remove special characters.\n",
    "          *  Remove single characters (e.g., stand-alone letters).\n",
    "          *  Replace multiple spaces with a single space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b87024b-da2c-46fe-8a09-b59f74598bd9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace, lower, col, length\n",
    "\n",
    "# Step 1: Remove rows with null or empty text\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.filter((col(\"text\").isNotNull()) & (length(col(\"text\")) > 0))\n",
    "\n",
    "# Step 2: Convert text to lowercase\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"text\", lower(col(\"text\")))\n",
    "\n",
    "# Step 3: Remove Twitter handles (@username)\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"text\", regexp_replace(col(\"text\"), r'@\\w+', ''))\n",
    "\n",
    "# Step 4: Remove hashtags (but keep the associated text)\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"text\", regexp_replace(col(\"text\"), r'#', ''))\n",
    "\n",
    "# Step 5: Remove URLs\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"text\", regexp_replace(col(\"text\"), r'http\\S+', ''))\n",
    "\n",
    "# Step 6: Remove all special characters (punctuation, emojis, etc.)\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"text\", regexp_replace(col(\"text\"), r'[^a-zA-Z\\s]', ''))\n",
    "\n",
    "# Step 7: Replace multiple spaces with a single space\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\s+', ' '))\n",
    "\n",
    "# Step 8: Verify that text is clean and consistent\n",
    "chatgpt_tweets_df_filtered.select(\"text\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "133441f5-941a-4ab2-b87e-560cbd1b2522",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Create a new column for the original tweet text\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df.withColumn(\"original_tweet\", col(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a6be554-1115-4c0b-8e91-2087fbf491dd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Convert 'tweet_created' to datetime format and remove timezone information\n",
    "\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"datetime\", to_timestamp(col(\"tweet_created\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73c2468f-1431-4daf-aca0-fb67d193f585",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Preprocess the tweet text (convert to lowercase)\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df.withColumn(\"text\", lower(col(\"text\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2ddec61c-c1e3-488f-b95f-c8935a4103e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Remove Twitter handles (@username)\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df.withColumn(\"text\", regexp_replace(col(\"text\"), r'@[^\\s]+', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0a5a1cb-58d3-43e7-aada-caf6cf6de840",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: Remove hashtags (#hashtag)\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\B#\\S+', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac4deb22-d0f6-4459-9ce1-355cf9c5f487",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Remove URLs\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df.withColumn(\"text\", regexp_replace(col(\"text\"), r'http\\S+', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "980cd399-f23c-4cc0-b4b0-6fd0f4c72432",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Remove all special characters, leaving only alphanumeric and spaces\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\W+', ' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17195b2f-2164-4fce-ac60-fc82a5cdf6b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 8: Remove all single characters\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\s+[a-zA-Z]\\s+', ''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2dd8f29-6c92-469c-ab59-fa1160d7f9cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 9: Substitute multiple spaces with a single space\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\s+', ' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebd46383-1d71-4b97-b4f5-96b1646ea808",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "chatgpt_tweets_df_filtered.filter((col(\"text\").isNull()) | (length(col(\"text\")) == 0)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7dee68f-5d11-41f3-91a5-9d4c791def0f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 10: Remove rows with null or empty in the 'text'\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.filter((col(\"text\").isNotNull()) & (length(col(\"text\")) > 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c9f3568-7cc8-4ca0-a58b-64abc4601600",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "# Create 'datetime' column from 'tweet_created'\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"datetime\", to_timestamp(col(\"tweet_created\")))\n",
    "\n",
    "# Show a sample of the DataFrame to ensure 'datetime' is created\n",
    "chatgpt_tweets_df_filtered.select(\"tweet_created\", \"datetime\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb01e01a-d389-419d-ad2e-dca51e9faf43",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(chatgpt_tweets_df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08e7f064-f2b6-4027-91b1-b19a4b6b69a5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Step 4: Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f780e36-f83b-4bf9-8c9b-167e1e2727c5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4.1  Extract Features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*      Tokenize the text into words and calculate:\n",
    "     *      Word count for each tweet.\n",
    "     *      Sentence length (total number of characters in the tweet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0becbf15-e18c-46e8-b6c3-56c71b5148f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, size, length, col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Step 1: Tokenization (Extract words)\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"words\", split(col(\"text\"), r\"\\W+\"))\n",
    "\n",
    "# Step 2: Word Count (Number of words)\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"words_count\", size(col(\"words\")))\n",
    "\n",
    "# Step 3: Sentence Length (Length of the sentence)\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"sentence_length\", length(col(\"text\")))\n",
    "\n",
    "# Show the extracted features\n",
    "chatgpt_tweets_df_filtered.select(\"text\", \"words\", \"words_count\", \"sentence_length\").show(5, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3d87e6f-c7da-4993-b5a7-7e9bc30a528d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4.2 Date and Time (Hour, Date, Month, Year)\n",
    "\n",
    "Extract hour, date, month, and year from the tweet_created column (now in datetime format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e7b4c84-8569-4997-8607-d0f2ec67dc6a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import hour, year, month, dayofmonth, date_format\n",
    "\n",
    "# Extract hour, date, month, year from the 'datetime' column\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"hour\", hour(col(\"datetime\")))\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"date\", date_format(col(\"datetime\"), \"yyyy-MM-dd\"))\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"month\", month(col(\"datetime\")))\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"year\", year(col(\"datetime\")))\n",
    "\n",
    "# Show the time-related features\n",
    "chatgpt_tweets_df_filtered.select(\"datetime\", \"hour\", \"date\", \"month\", \"year\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f199470b-1394-479f-91cc-f295b347bd6f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4.3 Sentiment Extraction using VADER\n",
    "\n",
    "*      Use VADER sentiment analysis to generate sentiment scores for each tweet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17e3d833-580c-4c93-91d4-21f041dd9102",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "For sentiment analysis, you can use VADER (from vaderSentiment library). Since VADER isn’t available directly in PySpark, you need to use a UDF (User Defined Function) to apply it across the Spark DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "942b2d0e-bd11-4af9-ba42-3f2e10657c08",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0449ac0e-0c9a-46f6-82fd-fb03ef81cf83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 4.3.1  Overall Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16438ca4-7d40-4498-b2fb-2d89377fb109",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "# Initialize the VADER sentiment analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a UDF to extract the compound sentiment score, handling None values\n",
    "def get_sentiment(text):\n",
    "    if text is None or len(text.strip()) == 0:  # Check if the text is None or empty\n",
    "        return 0.0  # Neutral score for missing/empty text\n",
    "    return float(sia.polarity_scores(text)['compound'])\n",
    "\n",
    "# Register the UDF in PySpark\n",
    "sentiment_udf = udf(get_sentiment, FloatType())\n",
    "\n",
    "# Apply the UDF to calculate sentiment score for each tweet on the filtered DataFrame\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"sentiment\", sentiment_udf(col(\"text\")))\n",
    "\n",
    "# Show the resulting DataFrame with sentiment scores\n",
    "chatgpt_tweets_df_filtered.select(\"text\", \"sentiment\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79ee7e54-8538-4e81-8952-3ddcece7b745",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4.3.2 Label the sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2169b6b-8412-402e-93c9-4efd3cd0eecd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def label_sentiment(score):\n",
    "    if score > 0.35:\n",
    "        return \"positive\"\n",
    "    elif score < -0.05:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "# Register the UDF for labeling\n",
    "label_udf = udf(label_sentiment, StringType())\n",
    "\n",
    "# Apply the UDF to create labeled sentiments\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"overall_sentiment\", label_udf(col(\"sentiment\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dfaedb5-3081-4aee-bc1a-460f025c8d5c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# check the dataframe\n",
    "display(chatgpt_tweets_df_filtered.select(\"text\", \"overall_sentiment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "277bf9af-0e70-43ea-8ed6-0f5ae7221938",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chatgpt_tweets_df_filtered.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0049a4c4-a594-498a-86ab-95f52882a171",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####   4.4 Convert Sentiment Labels To Numeric Form\n",
    "\n",
    "*      Use StringIndexer to convert the sentiment labels (negative, neutral, positive) into numeric form for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10be08b2-13ab-4795-93ca-056b19df2681",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Apply StringIndexer to the entire dataset\n",
    "indexer = StringIndexer(inputCol=\"overall_sentiment\", outputCol=\"overall_sentiment_index\")\n",
    "\n",
    "# Fit the indexer and apply it to the entire dataset\n",
    "chatgpt_tweets_df_encoded = indexer.fit(chatgpt_tweets_df_filtered).transform(chatgpt_tweets_df_filtered)\n",
    "\n",
    "# Check the encoded labels\n",
    "display(chatgpt_tweets_df_encoded.select(\"overall_sentiment\", \"overall_sentiment_index\").show(5))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89b9cf46-5b70-42cc-89dd-206daae9cc48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(chatgpt_tweets_df_encoded.select(\"overall_sentiment_index\", \"overall_sentiment\", \"text\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c61c4892-80bd-41c1-93fe-69db7a8926c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4.5 Handle Imbalance Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b493df1-b99f-4725-b357-2e3e1378257b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### 4.5.1 Check the Class distribution first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27fc921b-745e-403a-87fc-b4918a639891",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check class distribution in the dataset\n",
    "chatgpt_tweets_df_encoded.groupBy(\"overall_sentiment_index\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3dba961e-d7cc-4b4c-a66b-8383cd825ec7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Highly imbalanced data. So, We need to split the data first and then balance the train data itself, leaving the test portion to make it more realistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f8ddcc4-c516-415b-9d5d-5a525699e540",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4.5.2 Split the Data - Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "348340bc-a238-4cc8-b9b4-0b0f7d915f02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Split the dataset into 80% training and 20% testing sets\n",
    "train_df, test_df = chatgpt_tweets_df_encoded.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Check the class distribution in the training set\n",
    "train_df.groupBy(\"overall_sentiment_index\").count().show()\n",
    "\n",
    "# Check the class distribution in the test set (should remain imbalanced)\n",
    "test_df.groupBy(\"overall_sentiment_index\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21237404-d3ae-45dd-b2ae-c0d36df44c0b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 4.5.3 Undersample The Majority Class (neutral) in the Training Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "327eeea6-bf32-45a4-badb-fe6ec9c2cc69",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Now, let's undersample the neutral class (101,156 rows) in the training set to balance it with the positive (7,673 rows) and negative (5,021 rows) classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9322c7b1-7f5a-49b0-b5b2-a1a135825da4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Separate the classes in the training set\n",
    "neutral_train_df = train_df.filter(train_df[\"overall_sentiment_index\"] == 0)\n",
    "positive_train_df = train_df.filter(train_df[\"overall_sentiment_index\"] == 1)\n",
    "negative_train_df = train_df.filter(train_df[\"overall_sentiment_index\"] == 2)\n",
    "\n",
    "# Downsample the neutral class\n",
    "neutral_sampled_df = neutral_train_df.sample(withReplacement=False, fraction=0.1, seed=42)  # Adjust fraction to control the size\n",
    "\n",
    "# Combine the downsampled neutral class with positive and negative classes\n",
    "balanced_train_df = positive_train_df.union(negative_train_df).union(neutral_sampled_df)\n",
    "\n",
    "# Check the new class distribution in the balanced training set\n",
    "balanced_train_df.groupBy(\"overall_sentiment_index\").count().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec682885-415a-44dc-9b50-62d394db6ba2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This is significantly more balanced compared to the original distribution where the neutral class was heavily over-represented. While it's not perfectly equal, this distribution should work well for training ML model without the risk of overwhelming bias toward the neutral class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f49a5648-67c2-4abe-86d3-4e41ba3e8373",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9982125d-a0f5-4a19-b674-e08796884ee7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "####  4.6 Vectorize the Text Data (TF-IDF)\n",
    "\n",
    "\n",
    "*     Code to Vectorize the Text:\n",
    "         *     Tokenize the text.\n",
    "         *     Remove stopwords.\n",
    "         *     Apply HashingTF (term frequency).\n",
    "         *     Apply IDF (inverse document frequency) to get the TF-IDF features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88a61bf3-3382-4ecd-b96d-087770e8ce88",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Drop the conflicted columns and proceed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae3e254a-db55-4dd4-bf28-8c3c3c985653",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Step 1: Ensure all values in the 'text' column are strings\n",
    "balanced_train_df = balanced_train_df.withColumn(\"text\", col(\"text\").cast(\"string\"))\n",
    "chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.withColumn(\"text\", col(\"text\").cast(\"string\"))\n",
    "\n",
    "# Step 2: Drop conflicting columns from both DataFrames if they exist\n",
    "for column in ['tokenized_words', 'filtered_words', 'features', 'raw_features']:\n",
    "    if column in balanced_train_df.columns:\n",
    "        balanced_train_df = balanced_train_df.drop(column)\n",
    "    if column in chatgpt_tweets_df_filtered.columns:\n",
    "        chatgpt_tweets_df_filtered = chatgpt_tweets_df_filtered.drop(column)\n",
    "\n",
    "# Step 3: Proceed with Tokenization and TF-IDF\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Tokenize the text\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"tokenized_words\")\n",
    "\n",
    "# Remove stopwords\n",
    "remover = StopWordsRemover(inputCol=\"tokenized_words\", outputCol=\"filtered_words\")\n",
    "\n",
    "# Convert text into numerical features using TF-IDF\n",
    "hashingTF = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf])\n",
    "\n",
    "# Step 4: Fit the pipeline only on the training data\n",
    "pipeline_model = pipeline.fit(balanced_train_df)\n",
    "\n",
    "# Step 5: Transform the training and test data using the fitted pipeline\n",
    "balanced_train_df = pipeline_model.transform(balanced_train_df)\n",
    "test_df = pipeline_model.transform(test_df)\n",
    "\n",
    "# Step 6: Show the transformed data\n",
    "balanced_train_df.select(\"text\", \"tokenized_words\", \"filtered_words\", \"features\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57dadf21-c149-49d0-b73a-c956af07b610",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e917f8c0-c164-406f-9024-af7f2bdea0ef",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 5: ML models\n",
    "\n",
    "*    Train the Models \n",
    "*    LR, RF classifiers\n",
    "*    Evaluate the Models\n",
    "*    Model hyperparameter-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77f2e6db-3caa-4d95-8bf0-5876a0b6a74b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5.1  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9c1e9b0-ea9c-48c3-8dee-1527ffd61661",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"overall_sentiment_index\")\n",
    "\n",
    "# Train the Logistic Regression model using the balanced training data\n",
    "lr_model = lr.fit(balanced_train_df)\n",
    "\n",
    "# Make predictions on the test set\n",
    "lr_predictions = lr_model.transform(test_df)\n",
    "\n",
    "# Show the predictions\n",
    "display(lr_predictions.select(\"text\", \"overall_sentiment_index\", \"prediction\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0e9a3e5-e0c3-4ca7-ba52-20195b821f5a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "569df425-5090-4d4b-8b81-2af0824ee462",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c312322-0566-4c5c-890a-2357bac8347b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84e976b7-4c5f-43db-84a3-4c6028274703",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5.2 Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ac5d19c-8396-4674-bbd9-e778f1098976",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"overall_sentiment_index\", numTrees=100)\n",
    "\n",
    "# Train the Random Forest model using the balanced training data\n",
    "rf_model = rf.fit(balanced_train_df)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = rf_model.transform(test_df)\n",
    "\n",
    "# Show the predictions\n",
    "display(rf_predictions.select(\"text\", \"overall_sentiment_index\", \"prediction\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "565cfcb6-7253-4cbe-8628-970183538177",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4ceb5925-5678-4037-9532-3e6469acdcf1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "481259b2-0e84-4a17-8a17-5c7da49b1889",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 5.3: Model Evaluation \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52423b47-e448-4005-8e98-ed24748177f2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b64fc953-7b97-4c2e-b88d-7ca48ce5eb3f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize the evaluators\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "print(\"=== Logistic Regression Model Evaluation ===\")\n",
    "lr_accuracy = accuracy_evaluator.evaluate(lr_predictions)\n",
    "lr_precision = precision_evaluator.evaluate(lr_predictions)\n",
    "lr_recall = recall_evaluator.evaluate(lr_predictions)\n",
    "lr_f1 = f1_evaluator.evaluate(lr_predictions)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {lr_accuracy}\")\n",
    "print(f\"Logistic Regression Precision: {lr_precision}\")\n",
    "print(f\"Logistic Regression Recall: {lr_recall}\")\n",
    "print(f\"Logistic Regression F1 Score: {lr_f1}\")\n",
    "print()\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "print(\"=== Random Forest Model Evaluation ===\")\n",
    "rf_accuracy = accuracy_evaluator.evaluate(rf_predictions)\n",
    "rf_precision = precision_evaluator.evaluate(rf_predictions)\n",
    "rf_recall = recall_evaluator.evaluate(rf_predictions)\n",
    "rf_f1 = f1_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy}\")\n",
    "print(f\"Random Forest Precision: {rf_precision}\")\n",
    "print(f\"Random Forest Recall: {rf_recall}\")\n",
    "print(f\"Random Forest F1 Score: {rf_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae26bd1a-89a2-424c-9c05-5b601ea38314",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "balanced_train_df.cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82e7a71b-7da9-49a0-827a-4ac8d0e0e02e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dafc3526-4bb7-4880-8a36-e86679edb76e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 6:  ML models with Cross_validation, f-1 score, Model evaluation, Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cd6df6d-edcc-4cbe-bb2c-b439270723ed",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 6.1 Logistic Regression with K-fold :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3667e164-08db-471f-a561-b63cd281dec9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize Logistic Regression\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"overall_sentiment_index\")\n",
    "\n",
    "# Set up a smaller parameter grid for Logistic Regression\n",
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.1, 0.5]) \\\n",
    "    .build()\n",
    "\n",
    "# Define the evaluator using F1-score\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Set up the CrossValidator for Logistic Regression with fewer folds and params\n",
    "crossval_lr = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=paramGrid_lr,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3)  # Reduce folds to 3\n",
    "\n",
    "# Fit the Logistic Regression model with cross-validation\n",
    "cv_model_lr = crossval_lr.fit(balanced_train_df)\n",
    "\n",
    "# Make predictions on the test set\n",
    "lr_predictions = cv_model_lr.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea4123ee-f8bb-4ca9-bc79-b152935cb1e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(lr_predictions.select(\"text\", \"overall_sentiment_index\", \"prediction\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "76d58b2b-496a-469b-9a8e-da5d1277d772",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.2 Logistic Regression evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aef79dd8-e5fb-49cc-8dce-906febc3f00f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Evaluators for multiple metrics\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Evaluate Logistic Regression model\n",
    "lr_accuracy = accuracy_evaluator.evaluate(lr_predictions)\n",
    "lr_precision = precision_evaluator.evaluate(lr_predictions)\n",
    "lr_recall = recall_evaluator.evaluate(lr_predictions)\n",
    "lr_f1 = f1_evaluator.evaluate(lr_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Logistic Regression - Accuracy: {lr_accuracy}\")\n",
    "print(f\"Logistic Regression - Precision: {lr_precision}\")\n",
    "print(f\"Logistic Regression - Recall: {lr_recall}\")\n",
    "print(f\"Logistic Regression - F1 Score: {lr_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22de815b-bc43-4e51-92d9-dc397cc06f4d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.3  Random Forest Classifier with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f4a6478-e62a-4ed7-8b69-1416b1a8a732",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"overall_sentiment_index\")\n",
    "\n",
    "# Set up the parameter grid for Random Forest\n",
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50, 100]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "# Define the evaluator (using F1-score for tuning)\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Set up the CrossValidator for Random Forest\n",
    "crossval_rf = CrossValidator(\n",
    "    estimator=rf,\n",
    "    estimatorParamMaps=paramGrid_rf,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3)  # Use 3-fold cross-validation\n",
    "\n",
    "# Fit the Random Forest model with cross-validation\n",
    "cv_model_rf = crossval_rf.fit(balanced_train_df)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = cv_model_rf.transform(test_df)\n",
    "\n",
    "# Show the predictions\n",
    "display(rf_predictions.select(\"text\", \"overall_sentiment_index\", \"prediction\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c7d3600-3d2e-4380-a3a5-74b93158732c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.4 Random Forest Classifier evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d9ede534-7892-4ccd-9133-122875e63d79",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Evaluators for multiple metrics\n",
    "accuracy_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "precision_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "recall_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"overall_sentiment_index\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "# Evaluate Random Forest Classifier predictions\n",
    "rf_accuracy = accuracy_evaluator.evaluate(rf_predictions)\n",
    "rf_precision = precision_evaluator.evaluate(rf_predictions)\n",
    "rf_recall = recall_evaluator.evaluate(rf_predictions)\n",
    "rf_f1 = f1_evaluator.evaluate(rf_predictions)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Random Forest Classifier - Accuracy: {rf_accuracy}\")\n",
    "print(f\"Random Forest Classifier - Precision: {rf_precision}\")\n",
    "print(f\"Random Forest Classifier - Recall: {rf_recall}\")\n",
    "print(f\"Random Forest Classifier - F1 Score: {rf_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90900cc9-9caa-4e5f-a66b-499c94aed516",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.5 Decision Tree Classifier with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce9ae067-988a-410d-8780-acb93dfe467f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "# Initialize Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"overall_sentiment_index\")\n",
    "\n",
    "# Set up the parameter grid for tuning\n",
    "paramGrid_dt = ParamGridBuilder() \\\n",
    "    .addGrid(dt.maxDepth, [5, 10]) \\\n",
    "    .addGrid(dt.minInstancesPerNode, [1, 2]) \\\n",
    "    .build()\n",
    "\n",
    "# Set up the CrossValidator for Decision Tree\n",
    "crossval_dt = CrossValidator(\n",
    "    estimator=dt,\n",
    "    estimatorParamMaps=paramGrid_dt,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3)  # Use 3-fold cross-validation\n",
    "\n",
    "# Fit the Decision Tree model with cross-validation\n",
    "cv_model_dt = crossval_dt.fit(balanced_train_df)\n",
    "\n",
    "# Make predictions on the test set\n",
    "dt_predictions = cv_model_dt.transform(test_df)\n",
    "\n",
    "# Show predictions\n",
    "display(dt_predictions.select(\"text\", \"overall_sentiment_index\", \"prediction\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c18a9536-3670-4182-a40e-3e8fb9b6e205",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.6 RTC evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6e96719-98a7-4136-90d8-b99b9a5327c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate Decision Tree model\n",
    "dt_accuracy = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "dt_precision = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "dt_recall = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "dt_f1 = evaluator.evaluate(dt_predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Print Decision Tree evaluation metrics\n",
    "print(f\"Decision Tree Classifier - Accuracy: {dt_accuracy}\")\n",
    "print(f\"Decision Tree Classifier - Precision: {dt_precision}\")\n",
    "print(f\"Decision Tree Classifier - Recall: {dt_recall}\")\n",
    "print(f\"Decision Tree Classifier - F1 Score: {dt_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "035d6751-f83a-4651-843d-0e62b4a3237e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.7 Naive Bayes Classifier with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60774a3e-a0d5-4693-8524-0900891ba028",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Initialize Naive Bayes Classifier\n",
    "nb = NaiveBayes(featuresCol=\"features\", labelCol=\"overall_sentiment_index\")\n",
    "\n",
    "# Set up the parameter grid for tuning\n",
    "paramGrid_nb = ParamGridBuilder() \\\n",
    "    .addGrid(nb.smoothing, [0.0, 0.5, 1.0]) \\\n",
    "    .build()\n",
    "\n",
    "# Set up the CrossValidator for Naive Bayes\n",
    "crossval_nb = CrossValidator(\n",
    "    estimator=nb,\n",
    "    estimatorParamMaps=paramGrid_nb,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3)  # Use 3-fold cross-validation\n",
    "\n",
    "# Fit the Naive Bayes model with cross-validation\n",
    "cv_model_nb = crossval_nb.fit(balanced_train_df)\n",
    "\n",
    "# Make predictions on the test set\n",
    "nb_predictions = cv_model_nb.transform(test_df)\n",
    "\n",
    "# Show predictions\n",
    "display(nb_predictions.select(\"text\", \"overall_sentiment_index\", \"prediction\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5240522a-4855-4596-afb4-898dc1d87a72",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### 6.8 Naive Bayes classifier Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21aeb475-5170-4f0a-9ede-c567d06019f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate Naive Bayes model\n",
    "nb_accuracy = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"accuracy\"})\n",
    "nb_precision = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "nb_recall = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "nb_f1 = evaluator.evaluate(nb_predictions, {evaluator.metricName: \"f1\"})\n",
    "\n",
    "# Print Naive Bayes evaluation metrics\n",
    "print(f\"Naive Bayes Classifier - Accuracy: {nb_accuracy}\")\n",
    "print(f\"Naive Bayes Classifier - Precision: {nb_precision}\")\n",
    "print(f\"Naive Bayes Classifier - Recall: {nb_recall}\")\n",
    "print(f\"Naive Bayes Classifier - F1 Score: {nb_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77aa3c5c-c91b-4106-850b-595204a43d60",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 7: Model Selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae16699e-ceb4-453d-84a8-7b36fc7dff0a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Logistic Regression\n",
    " -   Logistic Regression - Accuracy: 0.8159488559892328 \n",
    " -   Logistic Regression - Precision: 0.8745705488045877\n",
    " -   Logistic Regression - Recall: 0.8159488559892328\n",
    " -   Logistic Regression - F1 Score: 0.8350467718837626"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7b32e46-d25e-4399-9566-c18591416200",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "After evaluating several machine learning models, Logistic Regression was selected as the best-performing model for the sentiment analysis task. This decision was based on the following key evaluation metrics:\n",
    "\n",
    "Accuracy: The Logistic Regression model achieved an accuracy of 81.6%, meaning it correctly predicted the sentiment label for over 80% of the data. This demonstrates that the model is highly reliable in predicting the correct sentiment.\n",
    "\n",
    "Precision: With a precision score of 87.5%, the model consistently predicted the correct class when it made a positive prediction. This high precision is important, as it shows that the model minimizes false positives, particularly in classifying positive sentiments.\n",
    "\n",
    "Recall: The recall score of 81.6% indicates that the model is able to identify a substantial proportion of the actual sentiment labels. This balance between precision and recall shows that the model is not biased towards any specific sentiment class.\n",
    "\n",
    "F1 Score: The F1 score of 83.5% strikes a good balance between precision and recall, confirming that the model performs well across all sentiment categories (positive, negative, and neutral). This makes Logistic Regression a strong candidate for accurately classifying various sentiment labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d89a8df4-5ddd-43bd-ba21-cdb8f6d62f87",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Step 8: Save prediction into my s3 bucket\n",
    "\n",
    "    * save as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b3b0c3d-f771-4565-b27a-727abe1e49cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"fs.s3a.access.key\", \"AKIA4VDBMHXDRBOBMLXQ\")\n",
    "spark.conf.set(\"fs.s3a.secret.key\", \"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\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e120175-1036-4264-a904-d3dc8e508329",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select only the necessary columns you want to save\n",
    "lr_predictions_flat = lr_predictions.select(\"text\", \"overall_sentiment_index\", \"prediction\")\n",
    "\n",
    "# Save the selected columns to S3 as a CSV\n",
    "lr_predictions_flat.write.format(\"csv\").save(\"s3a://boqi-bucket/sentiment_lr_predictions/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00f62ae7-0dde-4581-9d26-9c6029519bd8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Save the preprocessed data (with necessary columns) to S3 as a CSV\n",
    "chatgpt_tweets_df_filtered.select(*columns_to_keep) \\\n",
    "    .write.format(\"csv\").option(\"header\", \"true\").save(\"s3a://boqi-bucket/tweets_original_dat/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e023e80f-989a-45dc-826c-c92ccdbb4604",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(chatgpt_tweets_df_filtered.select(*columns_to_keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a57fc761-2e01-42cc-b28d-e7aad2081dfc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3397958963384793,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Big_Data_Project",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
